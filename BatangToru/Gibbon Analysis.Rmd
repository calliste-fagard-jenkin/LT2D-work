---
title: "Gibbon Analysis"
author: "Cal"
date: "22/06/2017"
output: html_document
---

```{r, echo=F, warning=F}
library(plotrix) # load the library needed to draw the arc on our graph
```
# Abstract
We perform a 2D detection function distance sampling analysis of a Gibbon
dataset (54 observations), using a development version of the LT2D
package. We modify the likelihood proposed by Borchers and Cox (2016), to
account for datasets for which detections have spikes of observations at radial 
distance close to, or at 0. We perform two analyses, one which excludes these 
observations, and one which does not. We find $\hat{p}$ to be XX, and XX for the
best model, for each of these cases, respectively. With 95% CIs (XX)
and (XX).

# Looking at the data:
```{r}
library('DEVDEV5') # load the development version of the LT2D package
Data = read.csv('GibbonSiamang.csv',header=T) # load the x and y data
Data = subset(Data, Data$Species == 1)
x = Data$PP.Distance ; y = Data$Forward.Distance
```

```{r, echo=FALSE}
# We produce some preliminary plots to see what the data look like: 
par(mfrow=c(1,3))

# we want to add a small amount of noise to data points at (0,0) to make it 
# clearer in the graph that there is a cluster here:
x_to_plot = x                                      # create vectors to 
y_to_plot = y                                      # fill with values

for (i in (1:length(x))){                          # loop through and add noise
  if (x[i]==0 & y[i]==0){                          # where it's required
    x_to_plot[i] = x[i] + runif(1,0,0.002)
    y_to_plot[i] = y[i] + runif(1,0,0.002)
  }         
}

pdlab="Perpendicular distance"
fdlab="Forward distance"
plot(x_to_plot,y_to_plot,pch="+",ylab=fdlab,xlab=pdlab)
rmin = sort(unique(Data$Radial.Distance))[2] # Calculate Rmin
draw.arc(0,0,radius=rmin,deg1=0,deg2=360,col="red",lwd=1)
legend(0.0113,0.065,"Radius Rmin",lty=1,col="red")
hist(y,breaks=seq(0,max(na.omit(y)),length=9),xlab=fdlab,main="")
hist(x,breaks=seq(0,max(na.omit(x)),length=13),xlab=pdlab,main="")

par(mfrow=c(1,1))
R = Data$Radial.Distance
hist(R, breaks = 22, main="Radial distances of detections")
```

It would seem by inspection, that 0.05 seems a reasonable perpendicular 
truncation distance ($w=0.05$), and 0.065 seems reasonable for $ystart$; the 
furthest forward distance at which we are able to detect animals. We have a
small cluster of values at distances close to (0,0), which is likely due to the 
rounding of recorded values in the field. Points at these coordinates have had 
a small amount of noise added to them in the scatter plot, to make the cluster
more visible. We notice a clear gap in the distribution of radial distances of 
detections between 0 and 0.0132, and so we take the latter of these values
to be rmin. 

# Dealing with rounded distances. 

The rounding down of small radial distances down to zero leads to loss of 
information; the true location of the detected animal could be at any radial
distance within $0$ to $R_{min}$, where $R_{min}$ is the value below which all
radial distances have been rounded to 0. We must reflect this uncertainty in
true location in our likelihood: 

$L_R(\boldsymbol{\beta};n)=
L_U(\boldsymbol{\beta};m)\times\Bigg[ 
\frac{\int_0^{R_{min}}
{\big\{{\large S}\left(y_{min}(x),\:x\:;\:\boldsymbol{\beta}\right)
-{\large S}\left(0,\:x\:;\:\boldsymbol{\beta}\right)\big\}
\pi(x\;;\:\boldsymbol{\phi})}\: dx}
{\int_0^w p(x\:;\:\boldsymbol{\beta})\:\pi(x\;;\:\boldsymbol{\phi}) \:dx}\Bigg]^{n-m}$

Where $L_U(\boldsymbol{\beta};m)$ is the Borchers and Cox (2016) likelihood,
evaluated at the m detections which have not been rounded down.
$y_{min}(x)$ is the forward distance at which an animal travelling from
$\infty$ to $0$ along the $y$ axis at perpendicular $x$ intersects the quarter
circle of radius $R_{min}$ and centre located at the observer's position. $S$ is
the Borchers and Cox (2016) survivor function, and all remaining parameters also
have the same definition as their presentation in Borchers and Cox (2016).

# Fitting models with the points at (0,0)
## Creating the data frame structure required for abundance estimation: 
```{r}
w=0.05;ystart=0.065 # set these to use in all our fits

stratum = rep(1, length(x))
transect = rep(1, length(x))
object = seq(1, length(x))
size = rep(1, length(x))
L = rep(4*52, length(x))
area = rep(4*52*2*w, length(x))

df = data.frame(y,x,stratum, transect, object, size, L, area)
df.zeros = df # so that we can use the data set with the zeros later, after 
# we've changed what df is
```

## H1 fits 
```{r,warning=F}
# H1 in the LT2D package is the Haynes and Buckland Hazard rate. 
# Normal bump with hazard h1:
b=c(-6.82664896,1.09392846) ; logphi=c(-0.03503625,0.51044374)  # start values

fit.h1 = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, rmin=rmin, hessian=TRUE)

fit.h1$fit$hessian
# par(mfrow=c(1,1))
# gof.LT2D(fit.n,plot=T)
# plot(fit.n,xbins=20,ybins=32,smooth.fy=TRUE,addrug=TRUE) 
# phatInterval(fit.n)*w #EHSW
# fit.n$p0 # p(0)

# Normal dip: --  bad ks gof in x --  problem with hessian inversion 
b=c(-6,1) ; logphi=c(1,-4)
fit.h1.chn = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.chnorm',
                 logphi=logphi,w=w, rmin=rmin, hessian=TRUE)
fit.h1.chn$ests

# Uniform with h1 -- bad ks gof in x -- 
b=c(-7.0744154,0.9876447)                 
fit.h1.unif = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, rmin=rmin, hessian=TRUE)
fit.h1.unif$ests
```

## ip1 fits
```{r, warning=F}
# ip1 with normal bump: -- bad ks gof in x -- p0 low --
b=list(5.2919208, -0.2205593, 8.4701307) ; logphi=c(0.01784102, -4.42209067)

fit.ip1 = LT2D.fit(DataFrameInput=df,hr='ip1',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, rmin=rmin, hessian=TRUE)
fit.ip1$ests

# uniform ip1
fit.ip1.unif = LT2D.fit(DataFrameInput=df,hr='ip1',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, rmin=rmin, hessian=TRUE)
fit.ip1.unif$ests
```

## ip0 fits
```{r, warning=F}
# Normal bump with ip0 hazard function: -- P0 estimated < 1 -- 
b=list(4.44687169, 7.73454600); logphi=c(8.60409236, 0.01086241)


fit.ip0 = LT2D.fit(DataFrameInput=df,hr='ip0',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, rmin=rmin, hessian=TRUE)
fit.ip0$ests

fit.ip0.unif = LT2D.fit(DataFrameInput=df,hr='ip0',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, rmin=rmin, hessian=TRUE)
fit.ip0.unif$ests
```
## Looking at AICs
```{r}
# H1 AICs
fit.h1$fit$AIC ; fit.h1.chn$fit$AIC ; fit.h1.unif$fit$AIC

# ip1 AICs 
fit.ip1$fit$AIC ; fit.ip1.unif$fit$AIC

#ip0 AICs 
fit.ip0$fit$AIC ; fit.ip0.unif$fit$AIC
```

# Fits which exclude the 3 points at (0,0)
## Creating the data frame structure required for abundance estimation: 
```{r}
df = data.frame(x,y)                  # fast way to remove all the 
df = subset(df, sqrt(x**2+y**2)>rmin) # (0,0) values
x = df$x ; y = df$y 

stratum = rep(1, length(x))
transect = rep(1, length(x))
object = seq(1, length(x))
size = rep(1, length(x))
L = rep(4*52, length(x))    # do we times this by the 52 visits? 
area = rep(4*52*2*w, length(x))

df = data.frame(y,x,stratum, transect, object, size, L, area)
```

## H1 fits 
```{r,warning=F}
# Normal bump with hazard h1:
b=list(-6.82664896,1.09392846) ; logphi=c(-0.03503625,0.51044374)  # start values

fit.h1.nz = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, hessian=TRUE)
fit.h1.nz$ests

# Normal dip: --- doesn't fit ---
b=list(-6,1) ; logphi=c(1,-3)
fit.h1.chn.nz = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.chnorm',
                 logphi=logphi,w=w, hessian=TRUE)
fit.h1.chn.nz$ests

# Uniform with h1 -- bad ks gof in x -- 
b = list(-7,1)
fit.h1.unif.nz = LT2D.fit(DataFrameInput=df,hr='h1',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, hessian=TRUE)
fit.h1.unif.nz$ests
```

## ip1 fits
```{r, warning=F}
# ip1 with normal bump: -- bad ks gof in x -- p0 low --
b = list(8.4300894,-4.4119375,1.2712169); logphi=c(3,0.8553059)
fit.ip1.nz = LT2D.fit(DataFrameInput=df,hr='ip1',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, hessian=TRUE)
fit.ip1.nz$ests
fit.ip1.nz$fit$par

# uniform ip1
fit.ip1.unif.nz = LT2D.fit(DataFrameInput=df,hr='ip1',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, hessian=TRUE)
fit.ip1.unif.nz$ests
```

## ip0 fits
```{r, warning=F}
# Normal bump with ip0 hazard function: -- P0 estimated < 1 -- 
b=list(4.44687169, 7.73454600); logphi=c(8.60409236, 0.01086241)


fit.ip0.nz = LT2D.fit(DataFrameInput=df,hr='ip0',b=b,ystart=ystart,pi.x='pi.norm',
                 logphi=logphi,w=w, hessian=TRUE)
fit.ip0.nz$ests

fit.ip0.unif.nz = LT2D.fit(DataFrameInput=df,hr='ip0',b=b,ystart=ystart,pi.x='pi.const',
                 logphi=NULL,w=w, hessian=TRUE)
fit.ip0.unif.nz$ests

```
## Looking at AICs
```{r}
# H1 AICs
fit.h1.nz$fit$AIC ; fit.h1.chn.nz$fit$AIC ; fit.h1.unif.nz$fit$AIC

# ip1 AICs 
fit.ip1.nz$fit$AIC ; fit.ip1.unif.nz$fit$AIC

#ip0 AICs 
fit.ip0.nz$fit$AIC ; fit.ip0.unif.nz$fit$AIC
```

# CDS anlysis of the data

```{r, warning=F, message=F}
library(Distance)
#df = df.zeros - we want to use the dataset with the zeros excluded 
# We add some columns to have the correct names
df$Area = df$area ; df$Sample.Label = df$transect ; df$Region.Label = df$stratum
df$distance = df$x ; df$Effort = df$L
df$x = NULL ; df$y = NULL


# fitting models:
mod.hn <- ds(data=df, transect = "line",
             key = "hn", adjustment = NULL, truncation = w, quiet = TRUE)
mod.hz <- ds(data=df, transect = "line",
             key = "hr", adjustment = NULL,truncation = w, quiet = TRUE)
mod.hn.cos <- ds(data=df, transect = "line",
                 key = "hn", adjustment = "cos",truncation = w, quiet = TRUE)
mod.hr.cos <- ds(data=df, transect = "line",
                 key = "hr", adjustment = "cos",truncation = w, quiet = TRUE)

summarize_ds_models(mod.hn, mod.hz, mod.hn.cos, mod.hr.cos)
```
```{r}
mod.hn$dht$individuals$N # Half normal detection function 
mod.hz$dht$individuals$N # Hazard rate detection function 
```
# Conclusions
Likelihoods with uniform perpendicular density functions tend to perform better 
by ${\Delta}AIC$ of 2 to 4 compared to likelihoods with non-uniform density, and 
the same hazard detection function. The data indicate there is little 
evidence to suggest gibbons display responsive movement to the observers. 

Likelihoods with the 4 points at (0,0) removed consistently produce lower AICs 
than those with the points included. 

The best model (H1 detection function with uniform perpendicular density and the 
values at (0,0) removed) produces an abundance estimate of 69 in the covered
sample area based on 50 detections. 

Models with uniform density produce lower abundance estimates. 

A CDS analysis produces point estimates which are significantly smaller than 
the LT2D estimates.

# Comparison between LT2D estimation and CDS for (0,0)s removed
```{r}
# Question 1: What are the AICs for CDS and LT2D? 
# A1: 
GOF = ds.gof(mod.hz, main = 'CDS') # CDS fit seems very reasonable... 
GOF
gof.LT2D(fit.h1.chn.nz, plot = TRUE)
plot(mod.hz, xlab="Distance / Km")
plot(fit.h1.unif.nz, xbins = 7)

# Fit seems fairly reasonable given the data... 

```